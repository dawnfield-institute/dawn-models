"""
Superfluid Memory for GAIA
Implements entropy-responsive fluid memory with macro-coherence structures.
See docs/architecture/modules/superfluid_memory.md for design details.
"""

import numpy as np
import time
import math
from typing import Dict, Any, List, Tuple, Optional, Union
from dataclasses import dataclass, field
from collections import defaultdict

# Import fracton core modules
from fracton.core.memory_field import MemoryField
from fracton.core.recursive_engine import ExecutionContext


@dataclass
class MemoryImprint:
    """Represents a stable structure in superfluid memory."""
    structure_id: str
    field_coordinates: Tuple[float, float, float]  # 3D position
    entropy_signature: float
    stability_score: float
    phase_coherence: float
    recursion_depth: int
    temporal_decay: float
    creation_time: float
    last_reinforcement: float
    reinforcement_count: int
    vortex_strength: float = 0.0


@dataclass
class VortexPattern:
    """Represents a coherent feedback loop in memory."""
    pattern_id: str
    center_coordinates: Tuple[float, float, float]
    radius: float
    angular_velocity: float
    stability_index: float
    participating_imprints: List[str]
    temporal_symmetry: float
    creation_time: float


class MemoryFieldTensor:
    """
    Dynamic 3D+ tensor storing symbolic field attractors.
    Functions as quantum-esque field trace of symbolic ancestry.
    """
    
    def __init__(self, shape: Tuple[int, int, int] = (32, 32, 16)):
        self.shape = shape
        self.field = np.zeros(shape, dtype=np.float32)
        self.entropy_density = np.zeros(shape, dtype=np.float32)
        self.phase_coherence = np.zeros(shape, dtype=np.float32)
        self.recursion_signature = np.zeros(shape, dtype=np.float32)
        
        # Track field evolution
        self.field_history = []
        self.update_count = 0
    
    def add_imprint(self, imprint: MemoryImprint, intensity: float = 1.0):
        """Add memory imprint to field tensor."""
        x, y, z = imprint.field_coordinates
        
        # Map coordinates to tensor indices
        ix = int(abs(x) * self.shape[0] / 20) % self.shape[0]
        iy = int(abs(y) * self.shape[1] / 20) % self.shape[1] 
        iz = int(abs(z) * self.shape[2] / 10) % self.shape[2]
        
        # Create Gaussian spread around imprint location
        sigma = 2.0
        for dx in range(-3, 4):
            for dy in range(-3, 4):
                for dz in range(-2, 3):
                    nx, ny, nz = (ix + dx) % self.shape[0], (iy + dy) % self.shape[1], (iz + dz) % self.shape[2]
                    distance = math.sqrt(dx*dx + dy*dy + dz*dz)
                    weight = intensity * math.exp(-distance*distance / (2*sigma*sigma))
                    
                    # Update field components
                    self.field[nx, ny, nz] += weight * imprint.stability_score
                    self.entropy_density[nx, ny, nz] += weight * imprint.entropy_signature
                    self.phase_coherence[nx, ny, nz] += weight * imprint.phase_coherence
                    self.recursion_signature[nx, ny, nz] += weight * imprint.recursion_depth / 10.0
    
    def apply_temporal_decay(self, decay_rate: float = 0.99):
        """Apply temporal decay to memory field."""
        self.field *= decay_rate
        self.entropy_density *= decay_rate
        self.phase_coherence *= decay_rate
        self.recursion_signature *= decay_rate
    
    def get_field_strength(self, coordinates: Tuple[float, float, float]) -> float:
        """Get field strength at given coordinates."""
        x, y, z = coordinates
        ix = int(abs(x) * self.shape[0] / 20) % self.shape[0]
        iy = int(abs(y) * self.shape[1] / 20) % self.shape[1]
        iz = int(abs(z) * self.shape[2] / 10) % self.shape[2]
        
        return float(self.field[ix, iy, iz])
    
    def find_attractors(self, threshold: float = 0.5) -> List[Tuple[int, int, int]]:
        """Find high-intensity regions that act as attractors."""
        attractors = []
        
        for ix in range(self.shape[0]):
            for iy in range(self.shape[1]):
                for iz in range(self.shape[2]):
                    if self.field[ix, iy, iz] > threshold:
                        # Check if this is a local maximum
                        is_maximum = True
                        current_val = self.field[ix, iy, iz]
                        
                        for dx in [-1, 0, 1]:
                            for dy in [-1, 0, 1]:
                                for dz in [-1, 0, 1]:
                                    if dx == 0 and dy == 0 and dz == 0:
                                        continue
                                    
                                    nx = (ix + dx) % self.shape[0]
                                    ny = (iy + dy) % self.shape[1]
                                    nz = (iz + dz) % self.shape[2]
                                    
                                    if self.field[nx, ny, nz] > current_val:
                                        is_maximum = False
                                        break
                                if not is_maximum:
                                    break
                            if not is_maximum:
                                break
                        
                        if is_maximum:
                            attractors.append((ix, iy, iz))
        
        return attractors


class StabilityEvaluator:
    """
    Analyzes incoming structures for long-term memory viability.
    Uses entropy convergence and recurrence frequency.
    """
    
    def __init__(self):
        self.structure_history = defaultdict(list)
        self.stability_threshold = 0.6
        self.recurrence_window = 100  # Time window for recurrence analysis
    
    def evaluate_stability(self, structure_data: Dict[str, Any], 
                          context: ExecutionContext) -> float:
        """Evaluate if structure should be stored in long-term memory."""
        structure_type = structure_data.get('type', 'unknown')
        entropy_resolved = structure_data.get('entropy_resolved', 0.0)
        
        # Record structure occurrence
        current_time = time.time()
        self.structure_history[structure_type].append({
            'timestamp': current_time,
            'entropy': entropy_resolved,
            'depth': context.depth or 0,
            'context_entropy': context.entropy
        })
        
        # Clean old history
        cutoff_time = current_time - self.recurrence_window
        self.structure_history[structure_type] = [
            entry for entry in self.structure_history[structure_type]
            if entry['timestamp'] > cutoff_time
        ]
        
        # Calculate stability metrics
        recurrence_frequency = len(self.structure_history[structure_type])
        entropy_convergence = self._calculate_entropy_convergence(structure_type)
        temporal_stability = self._calculate_temporal_stability(structure_type)
        depth_consistency = self._calculate_depth_consistency(structure_type)
        
        # Combine metrics
        stability_score = (
            0.3 * min(recurrence_frequency / 10.0, 1.0) +  # Frequency component
            0.25 * entropy_convergence +                    # Convergence component
            0.25 * temporal_stability +                     # Temporal component
            0.2 * depth_consistency                        # Depth component
        )
        
        return min(stability_score, 1.0)
    
    def _calculate_entropy_convergence(self, structure_type: str) -> float:
        """Calculate how much entropy values are converging."""
        history = self.structure_history[structure_type]
        if len(history) < 3:
            return 0.0
        
        entropies = [entry['entropy'] for entry in history[-10:]]  # Last 10 entries
        if len(entropies) < 2:
            return 0.0
        
        # Calculate variance - lower variance means more convergence
        variance = np.var(entropies)
        convergence = 1.0 / (1.0 + variance)  # Inverse relationship
        
        return convergence
    
    def _calculate_temporal_stability(self, structure_type: str) -> float:
        """Calculate temporal consistency of structure appearance."""
        history = self.structure_history[structure_type]
        if len(history) < 3:
            return 0.0
        
        timestamps = [entry['timestamp'] for entry in history]
        intervals = [timestamps[i+1] - timestamps[i] for i in range(len(timestamps)-1)]
        
        if not intervals:
            return 0.0
        
        # More regular intervals = higher stability
        interval_variance = np.var(intervals)
        stability = 1.0 / (1.0 + interval_variance / 100.0)  # Normalize
        
        return min(stability, 1.0)
    
    def _calculate_depth_consistency(self, structure_type: str) -> float:
        """Calculate consistency of recursion depth."""
        history = self.structure_history[structure_type]
        if len(history) < 2:
            return 0.0
        
        depths = [entry['depth'] for entry in history]
        depth_variance = np.var(depths)
        consistency = 1.0 / (1.0 + depth_variance)
        
        return min(consistency, 1.0)


class MemoryImrintEncoder:
    """
    Converts stable collapses into field imprints.
    Includes phase encoding and time decay signatures.
    """
    
    def __init__(self):
        self.imprint_counter = 0
        self.phase_offset = 0.0
    
    def encode_imprint(self, structure_data: Dict[str, Any], stability_score: float,
                      context: ExecutionContext) -> MemoryImprint:
        """Convert collapse result into memory imprint."""
        self.imprint_counter += 1
        
        # Calculate 3D coordinates from 2D plus depth
        base_coords = structure_data.get('coordinates', (0.0, 0.0))
        z_coord = (context.depth or 0) * 2.0  # Scale depth to z-dimension
        coordinates = (base_coords[0], base_coords[1], z_coord)
        
        # Calculate phase coherence
        phase_coherence = self._calculate_phase_coherence(structure_data, context)
        
        # Calculate temporal decay rate
        temporal_decay = self._calculate_decay_rate(stability_score)
        
        # Calculate vortex strength
        vortex_strength = self._calculate_vortex_strength(structure_data)
        
        imprint = MemoryImprint(
            structure_id=f"imprint_{self.imprint_counter}_{structure_data.get('type', 'unknown')}",
            field_coordinates=coordinates,
            entropy_signature=structure_data.get('entropy_resolved', 0.0),
            stability_score=stability_score,
            phase_coherence=phase_coherence,
            recursion_depth=context.depth or 0,
            temporal_decay=temporal_decay,
            creation_time=time.time(),
            last_reinforcement=time.time(),
            reinforcement_count=1,
            vortex_strength=vortex_strength
        )
        
        return imprint
    
    def _calculate_phase_coherence(self, structure_data: Dict[str, Any], 
                                  context: ExecutionContext) -> float:
        """Calculate phase coherence for the imprint."""
        # Use entropy and recursion depth to calculate phase
        entropy = structure_data.get('entropy_resolved', 0.0)
        depth = context.depth or 0
        
        # Phase calculation with harmonic components
        phase = (entropy * math.pi + depth * 0.5 + self.phase_offset) % (2 * math.pi)
        coherence = abs(math.cos(phase))  # Coherence based on phase alignment
        
        return coherence
    
    def _calculate_decay_rate(self, stability_score: float) -> float:
        """Calculate temporal decay rate based on stability."""
        # More stable structures decay slower
        base_decay = 0.99
        stability_bonus = stability_score * 0.01
        return min(base_decay + stability_bonus, 0.999)
    
    def _calculate_vortex_strength(self, structure_data: Dict[str, Any]) -> float:
        """Calculate potential for vortex formation."""
        # Structures with high curvature or force tend to form vortices
        curvature = structure_data.get('curvature', 0.0)
        force = structure_data.get('force', 0.0)
        
        vortex_strength = abs(curvature) * 0.5 + abs(force) * 0.3
        return min(vortex_strength, 1.0)


class VortexTracker:
    """
    Detects coherent feedback loops and orbiting patterns.
    Supports structural invariance in symbolic evolution.
    """
    
    def __init__(self, field_tensor: MemoryFieldTensor):
        self.field_tensor = field_tensor
        self.active_vortices = {}
        self.vortex_counter = 0
        self.detection_threshold = 0.4
    
    def detect_vortices(self, imprints: List[MemoryImprint]) -> List[VortexPattern]:
        """Detect vortex patterns in memory imprints."""
        new_vortices = []
        
        # Group imprints by proximity
        clusters = self._cluster_imprints(imprints)
        
        for cluster in clusters:
            if len(cluster) >= 3:  # Need at least 3 points for vortex
                vortex = self._analyze_cluster_for_vortex(cluster)
                if vortex and vortex.stability_index > self.detection_threshold:
                    new_vortices.append(vortex)
        
        # Update active vortices
        self._update_vortex_registry(new_vortices)
        
        return new_vortices
    
    def track_temporal_symmetry(self, vortex: VortexPattern, 
                               time_window: float = 10.0) -> float:
        """Track temporal symmetry in vortex evolution."""
        # Simplified temporal symmetry calculation
        # In a real implementation, this would analyze the vortex's evolution over time
        
        current_time = time.time()
        age = current_time - vortex.creation_time
        
        # Symmetry decreases with age unless reinforced
        base_symmetry = math.exp(-age / time_window)
        
        # Modify based on angular velocity (more regular = more symmetric)
        velocity_factor = 1.0 - abs(vortex.angular_velocity - 1.0)  # Optimal at velocity = 1.0
        
        temporal_symmetry = base_symmetry * velocity_factor
        return max(temporal_symmetry, 0.0)
    
    def _cluster_imprints(self, imprints: List[MemoryImprint]) -> List[List[MemoryImprint]]:
        """Group imprints by spatial proximity."""
        clusters = []
        used = set()
        
        for i, imprint in enumerate(imprints):
            if i in used:
                continue
            
            cluster = [imprint]
            used.add(i)
            
            # Find nearby imprints
            for j, other in enumerate(imprints):
                if j in used or j == i:
                    continue
                
                distance = self._calculate_3d_distance(
                    imprint.field_coordinates, 
                    other.field_coordinates
                )
                
                if distance < 5.0:  # Proximity threshold
                    cluster.append(other)
                    used.add(j)
            
            if len(cluster) > 1:
                clusters.append(cluster)
        
        return clusters
    
    def _analyze_cluster_for_vortex(self, cluster: List[MemoryImprint]) -> Optional[VortexPattern]:
        """Analyze cluster for vortex formation."""
        if len(cluster) < 3:
            return None
        
        # Calculate center of mass
        center_x = sum(imp.field_coordinates[0] for imp in cluster) / len(cluster)
        center_y = sum(imp.field_coordinates[1] for imp in cluster) / len(cluster)
        center_z = sum(imp.field_coordinates[2] for imp in cluster) / len(cluster)
        center = (center_x, center_y, center_z)
        
        # Calculate average distance (radius)
        distances = [self._calculate_3d_distance(center, imp.field_coordinates) for imp in cluster]
        radius = sum(distances) / len(distances)
        
        # Estimate angular velocity based on vortex strengths
        total_vortex_strength = sum(imp.vortex_strength for imp in cluster)
        angular_velocity = total_vortex_strength / len(cluster)
        
        # Calculate stability index
        stability_index = self._calculate_vortex_stability(cluster, center, radius)
        
        # Calculate temporal symmetry
        temporal_symmetry = 1.0  # Initialize high, will be updated over time
        
        self.vortex_counter += 1
        vortex = VortexPattern(
            pattern_id=f"vortex_{self.vortex_counter}",
            center_coordinates=center,
            radius=radius,
            angular_velocity=angular_velocity,
            stability_index=stability_index,
            participating_imprints=[imp.structure_id for imp in cluster],
            temporal_symmetry=temporal_symmetry,
            creation_time=time.time()
        )
        
        return vortex
    
    def _calculate_vortex_stability(self, cluster: List[MemoryImprint], 
                                   center: Tuple[float, float, float], 
                                   radius: float) -> float:
        """Calculate stability index for vortex pattern."""
        # Factors contributing to stability:
        # 1. Uniformity of distances from center
        # 2. Consistency of vortex strengths
        # 3. Phase coherence alignment
        
        distances = [self._calculate_3d_distance(center, imp.field_coordinates) for imp in cluster]
        distance_variance = np.var(distances) / max(radius * radius, 1e-10)
        distance_stability = 1.0 / (1.0 + distance_variance)
        
        vortex_strengths = [imp.vortex_strength for imp in cluster]
        strength_variance = np.var(vortex_strengths)
        strength_stability = 1.0 / (1.0 + strength_variance)
        
        phase_coherences = [imp.phase_coherence for imp in cluster]
        phase_consistency = sum(phase_coherences) / len(phase_coherences)
        
        # Combine stability factors
        stability = (0.4 * distance_stability + 
                    0.3 * strength_stability + 
                    0.3 * phase_consistency)
        
        return min(stability, 1.0)
    
    def _calculate_3d_distance(self, pos1: Tuple[float, float, float], 
                              pos2: Tuple[float, float, float]) -> float:
        """Calculate Euclidean distance in 3D."""
        return math.sqrt(
            (pos1[0] - pos2[0])**2 + 
            (pos1[1] - pos2[1])**2 + 
            (pos1[2] - pos2[2])**2
        )
    
    def _update_vortex_registry(self, new_vortices: List[VortexPattern]):
        """Update registry of active vortices."""
        current_time = time.time()
        
        # Remove old vortices
        expired_vortices = []
        for vortex_id, vortex in self.active_vortices.items():
            age = current_time - vortex.creation_time
            if age > 60.0 or vortex.stability_index < 0.2:  # 1 minute timeout or low stability
                expired_vortices.append(vortex_id)
        
        for vortex_id in expired_vortices:
            del self.active_vortices[vortex_id]
        
        # Add new vortices
        for vortex in new_vortices:
            self.active_vortices[vortex.pattern_id] = vortex


class SuperfluidMemory:
    """
    Main superfluid memory system coordinating all memory components.
    Manages entropy-responsive field with macro-coherence structures.
    """
    
    def __init__(self, field_shape: Tuple[int, int, int] = (32, 32, 16)):
        self.memory_field_tensor = MemoryFieldTensor(field_shape)
        self.stability_evaluator = StabilityEvaluator()
        self.imprint_encoder = MemoryImrintEncoder()
        self.vortex_tracker = VortexTracker(self.memory_field_tensor)
        
        # Storage for active imprints
        self.active_imprints = {}
        self.imprint_counter = 0
        
        # Statistics
        self.total_imprints_created = 0
        self.total_vortices_detected = 0
        self.memory_updates = 0
    
    def add_memory(self, structure_data: Dict[str, Any], 
                   context: ExecutionContext) -> Optional[MemoryImprint]:
        """Add new structure to superfluid memory if stable enough."""
        self.memory_updates += 1
        
        # Evaluate stability
        stability_score = self.stability_evaluator.evaluate_stability(structure_data, context)
        
        # Only store if above threshold
        if stability_score < self.stability_evaluator.stability_threshold:
            return None
        
        # Create memory imprint
        imprint = self.imprint_encoder.encode_imprint(structure_data, stability_score, context)
        
        # Add to active imprints
        self.active_imprints[imprint.structure_id] = imprint
        self.total_imprints_created += 1
        
        # Add to field tensor
        self.memory_field_tensor.add_imprint(imprint)
        
        # Check for vortex formation
        self._check_vortex_formation()
        
        return imprint
    
    def reinforce_memory(self, structure_id: str, reinforcement_strength: float = 1.0):
        """Reinforce existing memory imprint."""
        if structure_id in self.active_imprints:
            imprint = self.active_imprints[structure_id]
            imprint.last_reinforcement = time.time()
            imprint.reinforcement_count += 1
            
            # Strengthen in field tensor
            self.memory_field_tensor.add_imprint(imprint, reinforcement_strength)
    
    def get_memory_coherence(self, coordinates: Tuple[float, float, float]) -> float:
        """Get memory field coherence at given coordinates."""
        return self.memory_field_tensor.get_field_strength(coordinates)
    
    def get_memory_attractors(self, threshold: float = 0.5) -> List[Tuple[int, int, int]]:
        """Get current memory attractors (high-coherence regions)."""
        return self.memory_field_tensor.find_attractors(threshold)
    
    def update_memory_field(self):
        """Update memory field with temporal decay and maintenance."""
        # Apply temporal decay
        self.memory_field_tensor.apply_temporal_decay()
        
        # Remove weak imprints
        current_time = time.time()
        expired_imprints = []
        
        for imprint_id, imprint in self.active_imprints.items():
            age = current_time - imprint.last_reinforcement
            decay_factor = imprint.temporal_decay ** age
            
            if decay_factor < 0.1:  # Very weak
                expired_imprints.append(imprint_id)
        
        for imprint_id in expired_imprints:
            del self.active_imprints[imprint_id]
        
        # Update vortex tracking
        active_imprints_list = list(self.active_imprints.values())
        self.vortex_tracker.detect_vortices(active_imprints_list)
    
    def get_memory_statistics(self) -> Dict[str, Any]:
        """Get comprehensive memory statistics."""
        active_vortices = len(self.vortex_tracker.active_vortices)
        attractors = len(self.get_memory_attractors())
        
        avg_stability = 0.0
        if self.active_imprints:
            avg_stability = sum(imp.stability_score for imp in self.active_imprints.values()) / len(self.active_imprints)
        
        return {
            'active_imprints': len(self.active_imprints),
            'total_imprints_created': self.total_imprints_created,
            'active_vortices': active_vortices,
            'total_vortices_detected': self.total_vortices_detected,
            'memory_attractors': attractors,
            'average_stability': avg_stability,
            'memory_updates': self.memory_updates,
            'field_tensor_shape': self.memory_field_tensor.shape
        }
    
    def _check_vortex_formation(self):
        """Check for new vortex formation after adding imprint."""
        active_imprints_list = list(self.active_imprints.values())
        new_vortices = self.vortex_tracker.detect_vortices(active_imprints_list)
        
        if new_vortices:
            self.total_vortices_detected += len(new_vortices)
    
    def reset(self):
        """Reset superfluid memory to initial state."""
        self.memory_field_tensor = MemoryFieldTensor(self.memory_field_tensor.shape)
        self.stability_evaluator = StabilityEvaluator()
        self.imprint_encoder = MemoryImrintEncoder()
        self.vortex_tracker = VortexTracker(self.memory_field_tensor)
        
        self.active_imprints.clear()
        self.total_imprints_created = 0
        self.total_vortices_detected = 0
        self.memory_updates = 0
